{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-LsknjxtiNq",
        "outputId": "9f8c5167-0875-4fe9-ce7b-d987f03a51fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_path = \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "L_tOmG2v1-U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install numpy opencv-python-headless tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6xZVkxB2JAy",
        "outputId": "8b107a9e-2729-4fac-c713-b2bf5a3643bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
      ],
      "metadata": {
        "id": "C3qVoKw42Plf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1  # Puedes ajustar este valor según la disponibilidad de memoria\n",
        "lr = 1e-4  # 0.0001\n",
        "epochs = 40\n",
        "height = 960\n",
        "width = 540"
      ],
      "metadata": {
        "id": "4D576M9c22W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = os.path.join(drive_path, \"dataset\", \"non-aug\")\n",
        "files_dir = os.path.join(drive_path, \"Colab Notebooks\", \"files\", \"non-aug\")\n",
        "model_file = os.path.join(files_dir, \"unet-non-aug.h5\")\n",
        "log_file = os.path.join(files_dir, \"log-non-aug.csv\")"
      ],
      "metadata": {
        "id": "_-lAXqtX7Sjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "metadata": {
        "id": "tHH3wOaG4Kci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_dir(files_dir)"
      ],
      "metadata": {
        "id": "_UElGxR-40z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "GP6n7tii4NVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p"
      ],
      "metadata": {
        "id": "ihileGI05KxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_block(inputs, skip, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding=\"same\")(inputs)\n",
        "    x = tf.image.resize(x, [skip.shape[1], skip.shape[2]])  # Asegúrate de que las dimensiones coinciden\n",
        "    x = Concatenate()([x, skip])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Sg0flPv25OTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "    \"\"\"Encoder\"\"\"\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    \"\"\"Bridge\"\"\"\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    \"\"\"Decoder\"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "C7G9H9fv5YbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*\")))\n",
        "    train_y = sorted(glob(os.path.join(path, \"train\", \"masks\", \"*\")))\n",
        "    valid_x = sorted(glob(os.path.join(path, \"valid\", \"images\", \"*\")))\n",
        "    valid_y = sorted(glob(os.path.join(path, \"valid\", \"masks\", \"*\")))\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y)"
      ],
      "metadata": {
        "id": "8FBMXE-S5i3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (width, height))\n",
        "    x = x / 255.0\n",
        "    return x"
      ],
      "metadata": {
        "id": "0pttNhg_6fHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (width, height))\n",
        "    x = x / 255.0\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "m-uC8Gmn6kNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return tf.convert_to_tensor(x, dtype=tf.float32), tf.convert_to_tensor(y, dtype=tf.float32)\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([height, width, 3])\n",
        "    y.set_shape([height, width, 1])\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "MEAaTi076lzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_dataset(x, y, batch=batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "6wYU6ocC65dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_x, train_y), (valid_x, valid_y) = load_data(dataset_path)\n",
        "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3xjFfI_6-eZ",
        "outputId": "9b404612-6aff-46d7-b8a0-f6948ea895bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 455 - 455\n",
            "Valid: 455 - 455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)"
      ],
      "metadata": {
        "id": "1E0YUrUCFHqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in valid_dataset:\n",
        "    print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "J7Bh_9G2MoR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (height, width, 3)\n",
        "model = build_unet(input_shape)"
      ],
      "metadata": {
        "id": "xezdlU6nF4AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4MA2kkJF7mY",
        "outputId": "a0726b6a-9e31-4b8e-bbf7-f46c87f30276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 960, 540, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 960, 540, 64)         1792      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 960, 540, 64)         256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 960, 540, 64)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 960, 540, 64)         36928     ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 960, 540, 64)         256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 960, 540, 64)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 480, 270, 64)         0         ['activation_1[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 480, 270, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 480, 270, 128)        512       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 480, 270, 128)        0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 480, 270, 128)        147584    ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 480, 270, 128)        512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 480, 270, 128)        0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 240, 135, 128)        0         ['activation_3[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 240, 135, 256)        295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 240, 135, 256)        1024      ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 240, 135, 256)        0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 240, 135, 256)        590080    ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 240, 135, 256)        1024      ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 240, 135, 256)        0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 120, 67, 256)         0         ['activation_5[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 120, 67, 512)         1180160   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 120, 67, 512)         2048      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 120, 67, 512)         0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 120, 67, 512)         2359808   ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 120, 67, 512)         2048      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 120, 67, 512)         0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 60, 33, 512)          0         ['activation_7[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 60, 33, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 60, 33, 1024)         4096      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 60, 33, 1024)         0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 60, 33, 1024)         9438208   ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 60, 33, 1024)         4096      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 60, 33, 1024)         0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 120, 66, 512)         2097664   ['activation_9[0][0]']        \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " tf.image.resize (TFOpLambd  (None, 120, 67, 512)         0         ['conv2d_transpose[0][0]']    \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 120, 67, 1024)        0         ['tf.image.resize[0][0]',     \n",
            "                                                                     'activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 120, 67, 512)         4719104   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 120, 67, 512)         2048      ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 120, 67, 512)         0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 120, 67, 512)         2359808   ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 120, 67, 512)         2048      ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 120, 67, 512)         0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 240, 134, 256)        524544    ['activation_11[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " tf.image.resize_1 (TFOpLam  (None, 240, 135, 256)        0         ['conv2d_transpose_1[0][0]']  \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 240, 135, 512)        0         ['tf.image.resize_1[0][0]',   \n",
            " )                                                                   'activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 240, 135, 256)        1179904   ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 240, 135, 256)        1024      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 240, 135, 256)        0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 240, 135, 256)        590080    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 240, 135, 256)        1024      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 240, 135, 256)        0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 480, 270, 128)        131200    ['activation_13[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " tf.image.resize_2 (TFOpLam  (None, 480, 270, 128)        0         ['conv2d_transpose_2[0][0]']  \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 480, 270, 256)        0         ['tf.image.resize_2[0][0]',   \n",
            " )                                                                   'activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 480, 270, 128)        295040    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 480, 270, 128)        512       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 480, 270, 128)        0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 480, 270, 128)        147584    ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 480, 270, 128)        512       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 480, 270, 128)        0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 960, 540, 64)         32832     ['activation_15[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " tf.image.resize_3 (TFOpLam  (None, 960, 540, 64)         0         ['conv2d_transpose_3[0][0]']  \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 960, 540, 128)        0         ['tf.image.resize_3[0][0]',   \n",
            " )                                                                   'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 960, 540, 64)         73792     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 960, 540, 64)         256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 960, 540, 64)         0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 960, 540, 64)         36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 960, 540, 64)         256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 960, 540, 64)         0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 960, 540, 1)          65        ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31055297 (118.47 MB)\n",
            "Trainable params: 31043521 (118.42 MB)\n",
            "Non-trainable params: 11776 (46.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=lr, clipnorm=1.0)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"acc\"])"
      ],
      "metadata": {
        "id": "eUzMv9LnGJmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(model_file, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "    CSVLogger(log_file),\n",
        "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
        "]"
      ],
      "metadata": {
        "id": "bAu_olFrGMN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=valid_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuMCbF_eGOz4",
        "outputId": "34d42a32-4465-48f9-ac09-cfa0dda01a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.1435 - acc: 0.9585\n",
            "Epoch 1: val_loss improved from inf to 0.58256, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r455/455 [==============================] - 460s 917ms/step - loss: 0.1435 - acc: 0.9585 - val_loss: 0.5826 - val_acc: 0.7733 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.1406 - acc: 0.9515\n",
            "Epoch 2: val_loss improved from 0.58256 to 0.50779, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n",
            "455/455 [==============================] - 402s 884ms/step - loss: 0.1406 - acc: 0.9515 - val_loss: 0.5078 - val_acc: 0.8022 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.1270 - acc: 0.9531\n",
            "Epoch 3: val_loss did not improve from 0.50779\n",
            "455/455 [==============================] - 392s 861ms/step - loss: 0.1270 - acc: 0.9531 - val_loss: 0.6143 - val_acc: 0.8003 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.1105 - acc: 0.9576\n",
            "Epoch 4: val_loss did not improve from 0.50779\n",
            "455/455 [==============================] - 392s 862ms/step - loss: 0.1105 - acc: 0.9576 - val_loss: 1.0202 - val_acc: 0.7007 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0987 - acc: 0.9604\n",
            "Epoch 5: val_loss did not improve from 0.50779\n",
            "455/455 [==============================] - 392s 861ms/step - loss: 0.0987 - acc: 0.9604 - val_loss: 0.5098 - val_acc: 0.8280 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0911 - acc: 0.9626\n",
            "Epoch 6: val_loss improved from 0.50779 to 0.48317, saving model to /content/drive/MyDrive/Colab Notebooks/files/non-aug/unet-non-aug.h5\n",
            "455/455 [==============================] - 400s 880ms/step - loss: 0.0911 - acc: 0.9626 - val_loss: 0.4832 - val_acc: 0.7516 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0820 - acc: 0.9649\n",
            "Epoch 7: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 392s 861ms/step - loss: 0.0820 - acc: 0.9649 - val_loss: 0.6679 - val_acc: 0.6977 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0787 - acc: 0.9662\n",
            "Epoch 8: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 392s 861ms/step - loss: 0.0787 - acc: 0.9662 - val_loss: 0.6991 - val_acc: 0.7155 - lr: 1.0000e-04\n",
            "Epoch 9/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0698 - acc: 0.9683\n",
            "Epoch 9: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 392s 861ms/step - loss: 0.0698 - acc: 0.9683 - val_loss: 0.5883 - val_acc: 0.7208 - lr: 1.0000e-04\n",
            "Epoch 10/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0642 - acc: 0.9703\n",
            "Epoch 10: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 391s 861ms/step - loss: 0.0642 - acc: 0.9703 - val_loss: 0.5892 - val_acc: 0.7228 - lr: 1.0000e-04\n",
            "Epoch 11/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0776 - acc: 0.9661\n",
            "Epoch 11: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 338s 742ms/step - loss: 0.0776 - acc: 0.9661 - val_loss: 0.7529 - val_acc: 0.7056 - lr: 1.0000e-05\n",
            "Epoch 12/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0611 - acc: 0.9711\n",
            "Epoch 12: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 338s 743ms/step - loss: 0.0611 - acc: 0.9711 - val_loss: 0.7240 - val_acc: 0.6999 - lr: 1.0000e-05\n",
            "Epoch 13/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0543 - acc: 0.9734\n",
            "Epoch 13: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 392s 861ms/step - loss: 0.0543 - acc: 0.9734 - val_loss: 0.6982 - val_acc: 0.7005 - lr: 1.0000e-05\n",
            "Epoch 14/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0498 - acc: 0.9750\n",
            "Epoch 14: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 336s 739ms/step - loss: 0.0498 - acc: 0.9750 - val_loss: 0.6833 - val_acc: 0.7034 - lr: 1.0000e-05\n",
            "Epoch 15/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0593 - acc: 0.9717\n",
            "Epoch 15: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 392s 862ms/step - loss: 0.0593 - acc: 0.9717 - val_loss: 0.5908 - val_acc: 0.7110 - lr: 1.0000e-06\n",
            "Epoch 16/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0523 - acc: 0.9739\n",
            "Epoch 16: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 387s 852ms/step - loss: 0.0523 - acc: 0.9739 - val_loss: 0.5803 - val_acc: 0.7135 - lr: 1.0000e-06\n",
            "Epoch 17/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0489 - acc: 0.9752\n",
            "Epoch 17: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 390s 858ms/step - loss: 0.0489 - acc: 0.9752 - val_loss: 0.5795 - val_acc: 0.7140 - lr: 1.0000e-06\n",
            "Epoch 18/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.9760\n",
            "Epoch 18: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 389s 856ms/step - loss: 0.0471 - acc: 0.9760 - val_loss: 0.5829 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "Epoch 19/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0465 - acc: 0.9761\n",
            "Epoch 19: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 388s 854ms/step - loss: 0.0465 - acc: 0.9761 - val_loss: 0.5864 - val_acc: 0.7131 - lr: 1.0000e-07\n",
            "Epoch 20/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0459 - acc: 0.9763\n",
            "Epoch 20: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 335s 736ms/step - loss: 0.0459 - acc: 0.9763 - val_loss: 0.5883 - val_acc: 0.7128 - lr: 1.0000e-07\n",
            "Epoch 21/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0456 - acc: 0.9765\n",
            "Epoch 21: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 391s 861ms/step - loss: 0.0456 - acc: 0.9765 - val_loss: 0.5891 - val_acc: 0.7127 - lr: 1.0000e-07\n",
            "Epoch 22/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0454 - acc: 0.9766\n",
            "Epoch 22: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 391s 860ms/step - loss: 0.0454 - acc: 0.9766 - val_loss: 0.5895 - val_acc: 0.7127 - lr: 1.0000e-07\n",
            "Epoch 23/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0452 - acc: 0.9767\n",
            "Epoch 23: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 392s 861ms/step - loss: 0.0452 - acc: 0.9767 - val_loss: 0.5891 - val_acc: 0.7127 - lr: 1.0000e-08\n",
            "Epoch 24/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0452 - acc: 0.9767\n",
            "Epoch 24: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 335s 736ms/step - loss: 0.0452 - acc: 0.9767 - val_loss: 0.5893 - val_acc: 0.7127 - lr: 1.0000e-08\n",
            "Epoch 25/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0452 - acc: 0.9767\n",
            "Epoch 25: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 390s 857ms/step - loss: 0.0452 - acc: 0.9767 - val_loss: 0.5894 - val_acc: 0.7127 - lr: 1.0000e-08\n",
            "Epoch 26/40\n",
            "455/455 [==============================] - ETA: 0s - loss: 0.0452 - acc: 0.9767\n",
            "Epoch 26: val_loss did not improve from 0.48317\n",
            "455/455 [==============================] - 389s 856ms/step - loss: 0.0452 - acc: 0.9767 - val_loss: 0.5895 - val_acc: 0.7127 - lr: 1.0000e-08\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b16772acd00>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}